{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7721728c-f316-4e68-a719-7cd825426fac",
   "metadata": {},
   "source": [
    "# Notebook #4: Model Training on Federated Data\n",
    "\n",
    "#### Import the Rhino Health Python library & Authenticate to the Rhino Cloud\n",
    "We'll again import any necessary functions from the `rhino_health` library and authenticate to the Rhino Cloud. Please refer to Notebook #1 for an explanation of the `session` interface for interacting with various endpoints in the Rhino Health ecosystem. In addition, you can always find more information about the Rhino SDK on our <a target=\"_blank\" href=\"https://rhinohealth.github.io/rhino_sdk_docs/html/autoapi/index.html\">Official SDK Documentation</a> and on our <a target=\"_blank\" href=\"https://pypi.org/project/rhino-health/\" >PyPI Repository Page</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3890be-ff13-472e-901a-594fa99e9ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import rhino_health as rh\n",
    "from rhino_health.lib.endpoints.code_object.code_object_dataclass import (\n",
    "    CodeObjectCreateInput,\n",
    "    CodeObjectTypes,\n",
    "    CodeObjectRunInput,\n",
    "    CodeRunMultiDatasetInput,\n",
    "    ModelTrainInput \n",
    ")\n",
    "\n",
    "my_username = \"FCP_LOGIN_EMAIL\" # Replace this with the email you use to log into Rhino Health\n",
    "session = rh.login(username=my_username, password=getpass.getpass())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b96218-22e0-40c0-98c9-b1a9b0e3a84a",
   "metadata": {},
   "source": [
    "#### Retrieve Project and Dataset Information\n",
    "As you've surely noticed by this point, we'll start by instantiating a `Project` object. We'll continue specifying the same project name that we've been using throughout this guided sandbox experience. In addition, we'll retrieve the identifiers for the JPEG datasets that were produced in notebook #2 so that we can use them to train our AI model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe89328-be4c-4b6d-8a20-d166d98b828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = session.project.get_project_by_name(\"YOUR_PROJECT_NAME\")  # Replace with your project name\n",
    "\n",
    "datasets = project.datasets\n",
    "hco_cxr_dataset = project.get_datasets_by_name(\"mimic_cxr_hco_conv\")\n",
    "aidev_cxr_dataset = project.get_datasets_by_name(\"mimic_cxr_dev_conv\")\n",
    "cxr_datasets = [aidev_cxr_dataset.uid, hco_cxr_dataset.uid]\n",
    "print(f\"Loaded CXR Datasets '{hco_cxr_dataset.uid}', '{aidev_cxr_dataset.uid}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01cdbbf-ef6a-4260-80ea-2cf93eedccc6",
   "metadata": {},
   "source": [
    "#### Create a Code Object to generate distinct training and testing datasets\n",
    "When training any machine learning algorithm in a supervised fashion, we need to 'hold out' a segment of the data so that we can then use that held-out segment to generate an unbiased estimate of model performance. We can accomplish this using another container image that executes Python code to generate both a training set and a testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd94c56e-a079-42a4-aff2-29617489539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the container image that'll create the test-train split\n",
    "train_split_image_uri = \"MY CONTAINER IMAGE URI\"\n",
    "\n",
    "# get the schema that was created after JPG conversion\n",
    "cxr_schema = project.get_data_schema_by_name('mimic_cxr_hco_conv', project_uid=project.uid)\n",
    "cxr_schema_uid =cxr_schema.uid\n",
    "\n",
    "# create a code object using the container image\n",
    "test_train_split = CodeObjectCreateInput(\n",
    "    name=\"Train Test Split\",\n",
    "    description=\"Splitting data into train and test datasets per site\",\n",
    "    input_data_schema_uids=[cxr_schema_uid],\n",
    "    output_data_schema_uids=[None], # Auto-Generating the Output Data Schema for the Code Object\n",
    "    code_type=CodeTypes.GENERALIZED_COMPUTE,\n",
    "    project_uid = project.uid,\n",
    "    config={\"container_image_uri\": train_split_image_uri}\n",
    ")\n",
    "test_train_compute = session.code_object.create_code_object(test_train_split)\n",
    "print(f\"Got Code Object named '{test_train_compute.name}' with uid {test_train_compute.uid}\")\n",
    "\n",
    "# run the code object to create new datasets at each site\n",
    "run_params = CodeRunMultiDatasetInput(\n",
    "    code_object_uid= test_train_compute.uid,\n",
    "    input_dataset_uids=[aidev_cxr_dataset.uid, hco_cxr_dataset.uid],\n",
    "    output_dataset_naming_templates= ['{{ input_dataset_names.0 }} - Train', '{{ input_dataset_names.0 }} - Test'],\n",
    "    timeout_seconds=600,\n",
    "    sync=False,\n",
    ")\n",
    "\n",
    "print(f\"Starting to run {test_train_compute.name}\")\n",
    "code_run = session.code.run_code_object(run_params)\n",
    "run_result = code_run.wait_for_completion()\n",
    "print(f\"Finished running {test_train_compute.name}\")\n",
    "print(f\"Result status is '{run_result.status.value}', errors={run_result.result_info.get('errors') if run_result.result_info else None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6252401a-b01a-4a31-aa9c-23a835f25dc7",
   "metadata": {},
   "source": [
    "#### Use NVIDIA's FLARE framework to federate model training \n",
    "Rhino's platform includes a seamless integration of NVIDIA's Federated Learning framework (NVFlare), enabling you to train machine learning models collaboratively across distributed health data sources. This framework offers a few key advantages:\n",
    "\n",
    "1. **Secure Distributed Training**: NVFlare empowers users to conduct Federated Training across a network of healthcare institutions, each contributing their data insights without sharing raw data. This distributed approach ensures that sensitive patient information remains secure behind institutional firewalls.\n",
    "2. **NVIDIA GPU Acceleration**: NVFlare taps into the computational prowess of NVIDIA GPUs, expediting model training and optimization. This acceleration is a game-changer, reducing training time and enhancing the accuracy of models trained on massive healthcare datasets.\n",
    "3. **Versatility Across ML Frameworks**: NVFlare's framework compatibility extends to major machine learning frameworks such as PyTorch and TensorFlow. Adapt your existing machine learning code to NVFlare, ensuring seamless integration into the Federated Learning ecosystem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbc18df-73a6-4009-837b-217b5a7f4955",
   "metadata": {},
   "source": [
    "#### Create a code object for model training\n",
    "In the function call below, we must only pass the input and output data schemas. This is because we are only *defining* the code object in the below cell. We musn't pass the actual datasets until we execute the code object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1efeda7-cb4c-446f-ac95-19c5de6ed5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path for container image\n",
    "model_train_image_uri = \"YOUR CONTAINER URI\"\n",
    "\n",
    "# create code object to train the model using our container image\n",
    "flare_model = CodeObjectCreateInput(\n",
    "    name=\"Pneumonia Prediction Model Training\",\n",
    "    description=\"Pneumonia Prediction Model Training\",\n",
    "    input_data_schema_uids=[cxr_schema_uid],\n",
    "    output_data_schema_uids=[None], # Auto-Generating the Output Data Schema for the Code Object\n",
    "    project_uid= project.uid,\n",
    "    model_type=CodeTypes.NVIDIA_FLARE_V2_2,\n",
    "    config={\"container_image_uri\": model_train_image_uri}\n",
    ")\n",
    "\n",
    "flare_model = session.code_object.create_code_object(flare_model)\n",
    "print(f\"Got FLARE model '{flare_model.name}' with uid {flare_model.uid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1b79e0-84bb-42b5-9729-1adc3d124ea8",
   "metadata": {},
   "source": [
    "#### Run the model training code object\n",
    "When it comes time to actually execute our model training process, we can pass the code object's unique identifier to the function that executes the container image. We'll pass both the training and testing data to the function. Note that the `config_*` and `secrets_*` arguments can be left blank because we are required to pass neither a configuration for the federated server nor the federated configuration file associated with all NVFlare implementations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92c2b1d-e98d-4b48-8c2c-07852b5e1c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve training Dataset\n",
    "input_training_datasets = session.dataset.search_for_datasets_by_name('Train')\n",
    "print(['Training Datasets: ' + x.name for x in input_training_datasets])\n",
    "\n",
    "# retrieve testing Dataset\n",
    "input_validation_datasets =  session.dataset.search_for_datasets_by_name('Test')\n",
    "print(['Testing Datasets: ' + x.name for x in input_validation_datasets])\n",
    "\n",
    "run_params = ModelTrainInput(\n",
    "    code_object_uid=flare_model.uid,\n",
    "    input_dataset_uids=[x.uid for x in input_training_datasets], \n",
    "    simulate_federated_learning=True ,        \n",
    "    validation_dataset_uids=[x.uid for x in input_validation_datasets], \n",
    "    validation_datasets_inference_suffix=\" - Pneumonia training results\",\n",
    "    timeout_seconds=600,\n",
    "    config_fed_server=\"\",\n",
    "    config_fed_client=\"\",\n",
    "    secrets_fed_client=\"\",\n",
    "    secrets_fed_server=\"\",\n",
    "    sync=False,\n",
    ")\n",
    "\n",
    "print(f\"Starting to run federated training of {flare_model.name}\")\n",
    "model_train = session.code_object.train_model(run_params)\n",
    "train_result = model_train.wait_for_completion()\n",
    "print(f\"Finished running {flare_model.name}\")\n",
    "print(f\"Result status is '{train_result.status.value}', errors={train_result.result_info.get('errors') if train_result.result_info else None}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

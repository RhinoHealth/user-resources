{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14ba6e95",
   "metadata": {},
   "source": [
    "# Fitting Federated Generalized Linear Model (GLM) coefficients with FCP\n",
    "Demonstrate usage of the Rhino Health Python SDK for running GLM via NVFlare and extracting the coefficients\n",
    "\n",
    "#### Prerequisites \n",
    "1. Have two datasets imported into FCP with variables on which you want to run the regression (e.g. 'Y', 'X', 'COV1', 'COV2', 'COV3', and 'COV4' in this example)\n",
    "2. Build a container from the NVFlare-based GLM code from this example and push it to your ECR repo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4793120",
   "metadata": {},
   "source": [
    "### Initialization and Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c14d5547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import rhino_health as rh\n",
    "from rhino_health.lib.endpoints.code_object.code_object_dataclass import (\n",
    "    CodeObject,\n",
    "    CodeObjectCreateInput,\n",
    "    CodeTypes,\n",
    "    ModelTrainInput\n",
    ")\n",
    "from rhino_health.lib.endpoints.endpoint import NameFilterMode\n",
    "from rhino_health.lib.constants import ApiEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89cd29cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rhino-health in /Users/danieldavid/.pyenv/versions/3.11.6/lib/python3.11/site-packages (1.5.1)\n",
      "Requirement already satisfied: arrow<2.0,>=1.2.1 in /Users/danieldavid/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from rhino-health) (1.3.0)\n",
      "Requirement already satisfied: backoff<3.0,>=2.1.1 in /Users/danieldavid/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from rhino-health) (2.2.1)\n",
      "Requirement already satisfied: funcy<3.0,>=1.16 in /Users/danieldavid/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from rhino-health) (2.0)\n",
      "Requirement already satisfied: pydantic<3.0,>=2.5 in /Users/danieldavid/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from rhino-health) (2.5.3)\n",
      "Requirement already satisfied: ratelimit<3.0,>=2.2.1 in /Users/danieldavid/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from rhino-health) (2.2.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.28 in /Users/danieldavid/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from rhino-health) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions<5.0,>=4.8.0 in /Users/danieldavid/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from rhino-health) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in /Users/danieldavid/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from arrow<2.0,>=1.2.1->rhino-health) (2.9.0.post0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /Users/danieldavid/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from arrow<2.0,>=1.2.1->rhino-health) (2.9.0.20241206)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/danieldavid/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pydantic<3.0,>=2.5->rhino-health) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /Users/danieldavid/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from pydantic<3.0,>=2.5->rhino-health) (2.14.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/danieldavid/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from requests<3.0,>=2.28->rhino-health) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/danieldavid/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from requests<3.0,>=2.28->rhino-health) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/danieldavid/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from requests<3.0,>=2.28->rhino-health) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/danieldavid/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from requests<3.0,>=2.28->rhino-health) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in /Users/danieldavid/.pyenv/versions/3.11.6/lib/python3.11/site-packages (from python-dateutil>=2.7.0->arrow<2.0,>=1.2.1->rhino-health) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade rhino-health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb8304c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging In\n",
      "Logged In\n"
     ]
    }
   ],
   "source": [
    "my_username = \"daniel.david@rhinohealth.com\" # Replace this with the email you use to log into Rhino Health\n",
    "\n",
    "print(\"Logging In\")\n",
    "session = rh.login(username=my_username, password=getpass.getpass(),rhino_api_url= ApiEnvironment.STAGING_AWS_URL)\n",
    "print(\"Logged In\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fc5fd9",
   "metadata": {},
   "source": [
    "### Load the project, datasets, and data schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1100670",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_project_name = \"regression-logistic-linear\"  # Replace this with your project name on Rhino Health\n",
    "project = session.project.get_project_by_name(my_project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c968e11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 datasets with the name glm\n",
      "Dataset names: ['glm_coeff_dataset1', 'glm_coeff_dataset2']\n"
     ]
    }
   ],
   "source": [
    "dataset_search_string = \"glm\"  # Replace this with a string that exists in all of the relevant datasets' names\n",
    "datasets = project.search_for_datasets_by_name(dataset_search_string, name_filter_mode=NameFilterMode.CONTAINS)\n",
    "schema = datasets[0].data_schema\n",
    "\n",
    "print(f\"Found {len(datasets)} datasets with the name {dataset_search_string}\")\n",
    "# print(f\"Schema: {json.dumps(schema, indent=2)}\")\n",
    "print(f\"Dataset names: {[dataset.name for dataset in datasets]}\")\n",
    "\n",
    "# Note: There are multiple ways to retrive datasets using the SDK, this examples relies on the datasets having similar names, such as \"MyDataset 1\" and \"MyDataset 2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f95651f",
   "metadata": {},
   "source": [
    "### Create the code object with the desired configuration (including regression formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac20344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_base_ecr_uri = \"rhino-gc-workgroup-rhino-health-staging\"  # Replace this with your workgroup ecr uri\n",
    "image_name = \"regression-glm-coeff_dd_v0.1\"  # Replace the name of the docker image uploaded to your ecr, containing the GLM regression using nvflare code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a88e990",
   "metadata": {},
   "source": [
    "#### Define the config (regression formula, regression family, optimization method, etc.) in the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98520eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"Yb ~ Xb + COV1 + COV2 + COV3 + COV4\"\n",
    "method = \"IRLS\"  # Meaning we'll be using IRLS for optimization and not Newton Raphson\n",
    "glm_type = \"Binomial\"  # Meaning we'll be using a logistic regression\n",
    "config_fed_client_path = \"/Users/danieldavid/user-resources/examples/nvflare/regression-glm-coeff/config/config_fed_client.json\"  # Replace this with the path to your config client file\n",
    "\n",
    "with open(config_fed_client_path) as f:\n",
    "    config_fed_client_input = json.loads(f.read())\n",
    "\n",
    "# Define the formula to use for the regression\n",
    "config_fed_client_input['executors'][0]['executor']['args']['formula'] = formula\n",
    "config_fed_client_input['executors'][0]['executor']['args']['method'] = method\n",
    "config_fed_client_input['executors'][0]['executor']['args']['glm_type'] = glm_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689db4ac",
   "metadata": {},
   "source": [
    "#### Create the Code Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66badbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got code object 'GLM Model Name' with uid 6446213a-1157-4684-8d77-588e23288363\n"
     ]
    }
   ],
   "source": [
    "code_object_config = CodeObjectCreateInput(\n",
    "    name=f'GLM Model Name', \n",
    "    description=\"GLM\",\n",
    "    input_data_schema_uids=[schema.uid],\n",
    "    output_data_schema_uids=[None],\n",
    "    project_uid= project.uid, \n",
    "    code_type=CodeTypes.NVIDIA_FLARE_V2_3, \n",
    "    config={\"container_image_uri\": image_name} \n",
    ")\n",
    "\n",
    "code_object = session.code_object.create_code_object(code_object_config)\n",
    "print(f\"Got code object '{code_object.name}' with uid {code_object.uid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75a4d07",
   "metadata": {},
   "source": [
    "### Run the federated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5035c085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to run federated training of GLM Model Name\n",
      "Waiting for code run to complete (0 hours 0 minutes and a second)\n",
      "Waiting for code run to complete (0 hours 0 minutes and 11 seconds)\n",
      "Waiting for code run to complete (0 hours 0 minutes and 22 seconds)\n",
      "Done.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CodeRun' object has no attribute 'results_info'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m code_run_uid \u001b[38;5;241m=\u001b[39m model_train\u001b[38;5;241m.\u001b[39mcode_run_uid\n\u001b[1;32m     19\u001b[0m run_result \u001b[38;5;241m=\u001b[39m model_train\u001b[38;5;241m.\u001b[39mwait_for_completion()\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResult status is \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_result\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, errors=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_result\u001b[38;5;241m.\u001b[39mresults_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merrors\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[43mrun_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresults_info\u001b[49m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.6/lib/python3.11/site-packages/pydantic/main.py:761\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[0;32m--> 761\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CodeRun' object has no attribute 'results_info'"
     ]
    }
   ],
   "source": [
    "config_fed_server_input = '/Users/danieldavid/user-resources/examples/nvflare/regression-glm-coeff/config/config_fed_client.json'\n",
    "run_params = ModelTrainInput(\n",
    "    code_object_uid=code_object.uid, \n",
    "    input_dataset_uids=[dataset.uid for dataset in datasets],\n",
    "    one_fl_client_per_dataset=True,\n",
    "    validation_dataset_uids=[], \n",
    "    validation_datasets_inference_suffix=\"\",\n",
    "    timeout_seconds=600,\n",
    "    config_fed_server=json.dumps(config_fed_server_input), \n",
    "    config_fed_client=json.dumps(config_fed_client_input), \n",
    "    secrets_fed_client=\"\",\n",
    "    secrets_fed_server=\"\", \n",
    "    sync=False,\n",
    ")\n",
    "\n",
    "print(f\"Starting to run federated training of {code_object.name}\")\n",
    "model_train = session.code_object.train_model(run_params)\n",
    "code_run_uid = model_train.code_run_uid\n",
    "run_result = model_train.wait_for_completion()\n",
    "print(f\"Result status is '{run_result.status.value}', errors={run_result.results_info.get('errors') if run_result.results_info else None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1393d32",
   "metadata": {},
   "source": [
    "### Load and display the resulting coefficients and stderrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2570ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fa05f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = np.load(session.code_run.get_model_params(code_run_uid), allow_pickle=True)\n",
    "\n",
    "scalar_value = model_output.item()\n",
    "betas = scalar_value['beta'] \n",
    "stderrs = scalar_value['fed_stderror']\n",
    "print(\"Beta      (Stderr)\\n\" + \"\\n\".join([f\"{beta} ({stderr})\" for beta, stderr in (zip(betas, stderrs))]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

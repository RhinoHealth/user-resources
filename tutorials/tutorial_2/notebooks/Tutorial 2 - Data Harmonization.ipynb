{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Multi-Dataset Data Harmonization\n",
    "\n",
    "### Demonstrating how to script data harmonization, dataset import, and reusable ETLs with the Rhino Health Python SDK.\n",
    "\n",
    "## 1. Load All Necessary Libraries\n",
    "### Ensure that you are running this notebook in the correct kernel.\n",
    "### If needed, install the required libraries by uncommenting the following line. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade rhino_health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from getpass import getpass\n",
    "import rhino_health as rh\n",
    "from rhino_health.lib.endpoints.dataset.dataset_dataclass import DatasetCreateInput\n",
    "from rhino_health.lib.endpoints.code_object.code_object_dataclass import (\n",
    "    CodeObjectCreateInput,\n",
    "    CodeTypes,\n",
    "    CodeObjectRunInput,\n",
    ")\n",
    "from rhino_health import ApiEnvironment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Logging into the Rhino Health Platform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace the Values with the following Variables below\n",
    "1. my_nusername - This should be your username that you use to log into the Rhino Health Platform\n",
    "2. my_password - This should be your password that you use to log into the Rhino Health Platform\n",
    "3. project_uid - Copy the UID from the project you just created in the UI by navigating to the homepage, pressing on the three verticle dot button in your project's square and then selecting the button _Copy UID_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_username = 'USERNAME'                                             \n",
    "project_uid = \"XXXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\"                   # Paste your project uid here as a string\n",
    "\n",
    "print(\"Logging In\")\n",
    "session = rh.login(username=my_username, password=getpass())\n",
    "print(\"Logged In\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Import Datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1  Collect all Necessary Parameters for Importing your dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workgroup = session.project.get_collaborating_workgroups(project_uid)[0]\n",
    "dataschema = session.project.get_data_schemas(project_uid)[0]\n",
    "print(f\"Loaded dataschema '{dataschema.name}' with uid '{dataschema.uid}'\")\n",
    "\n",
    "# Replace the paths here according to where you placed the files on you client\n",
    "dataset1_part1_path = \"/rhino_data/tutorial_2/datasets/site1_part1_dataset.csv\"\n",
    "dataset2_part1_path = \"/rhino_data/tutorial_2/datasets/site2_part1_dataset.csv\"\n",
    "dataset3_part1_path = \"/rhino_data/tutorial_2/datasets/site3_part1_dataset.csv\"\n",
    "\n",
    "# Alternatively, if you have access to the access to client-mounted storage, use something like the following:\n",
    "\n",
    "# dataset1_part1_path = \"/rhino_data/external/s3/tutorial_2/site1_part1_dataset.csv\"\n",
    "# dataset2_part1_path = \"/rhino_data/external/s3/tutorial_2/site2_part1_dataset.csv\"\n",
    "# dataset3_part1_path = \"/rhino_data/external/s3/tutorial_2/site3_part1_dataset.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Trigger dataset import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_creation_params = DatasetCreateInput(\n",
    "    name=\"Site 1 Dataset\",\n",
    "    description=\"Diabetes dataset for site 1\",\n",
    "    project_uid=project_uid, \n",
    "    workgroup_uid=workgroup.uid,\n",
    "    data_schema_uid=dataschema.uid,\n",
    "    csv_filesystem_location=dataset1_part1_path,\n",
    "    is_data_deidentified=True,\n",
    "    method=\"filesystem\",\n",
    ")\n",
    "\n",
    "site1_dataset = session.dataset.add_dataset(dataset_creation_params)\n",
    "print(f\"Created new dataset '{site1_dataset.name}' with uid '{site1_dataset.uid}'\")\n",
    "\n",
    "dataset_creation_params = DatasetCreateInput(\n",
    "    name=\"Site 2 Dataset\",\n",
    "    description=\"Diabetes dataset for site 2\",\n",
    "    project_uid=project_uid, \n",
    "    workgroup_uid=workgroup.uid,\n",
    "    data_schema_uid=dataschema.uid,\n",
    "    csv_filesystem_location=dataset2_part1_path,\n",
    "    is_data_deidentified=True,\n",
    "    method=\"filesystem\",\n",
    ")\n",
    "\n",
    "site2_dataset = session.dataset.add_dataset(dataset_creation_params)\n",
    "print(f\"Created new dataset '{site2_dataset.name}' with uid '{site2_dataset.uid}'\")\n",
    "\n",
    "dataset_creation_params = DatasetCreateInput(\n",
    "    name=\"Site 3 Dataset\",\n",
    "    description=\"Diabetes dataset for site 3\",\n",
    "    project_uid=project_uid, \n",
    "    workgroup_uid=workgroup.uid,\n",
    "    data_schema_uid=dataschema.uid,\n",
    "    csv_filesystem_location=dataset3_part1_path,\n",
    "    is_data_deidentified=True,\n",
    "    method=\"filesystem\",\n",
    ")\n",
    "\n",
    "site3_dataset = session.dataset.add_dataset(dataset_creation_params)\n",
    "print(f\"Created new dataset '{site3_dataset.name}' with uid '{site3_dataset.uid}'\")\n",
    "print(\"You should now have 3 new datasets in the project within the GUI. Feel free to take a look!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Harmonize Datasets Using Containerless GC\n",
    "By reviewing the dataset analytics on the GUI, you can see several inconsistencies across the 3 datasets (specifically for 'Outcome', 'Weight', 'Height' and 'SkinThickness'). These kinds of inconsistencies can often occur when collecting data from multiple sources. \n",
    "\n",
    "In this next part, you will use simple pandas operations to produce harmonized versions of these datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Define harmonization code for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_1_code = \"df.replace({'Outcome': { 'Positive': 1, 'Negative': 0}}, inplace=True)\\ndf.Weight = round(df.Weight*0.453592, 0).astype(int)\"\n",
    "site_2_code = \"df['SkinThickness'] = df['SkinThickness']*100\\ndf['Height'] = df['Height']/100\"\n",
    "site_3_code = \"df.replace({'Outcome': { 'Positive': 1, 'Negative': 0}},inplace=True)\\ndf['Pregnancies'].replace('None', 0, inplace=True)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Site 1 Data Harmonization by Defining a Run of Our Code Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting to run harmonization on site 1 data\")\n",
    "output_dataset, run_results = site1_dataset.run_code(site_1_code, output_data_schema_uid=dataschema.uid, output_dataset_names_suffix=\" Fixed\")\n",
    "print(\"Finished running harmonization on site 1 data\")\n",
    "\n",
    "print(\"You can now see a new dataset in the GUI named 'Site 1 Dataset Fixed'\")\n",
    "print(\"View the Results below\")\n",
    "run_results.raw_response().json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Site 2 Data Harmonization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting to run harmonization on site 2 data\")\n",
    "output_dataset, run_results = site2_dataset.run_code(site_2_code, output_data_schema_uid=dataschema.uid, output_dataset_names_suffix=\" Fixed\")\n",
    "print(\"Finished running harmonization on site 2 data\")\n",
    "\n",
    "print(\"You can now see a new dataset in the GUI named 'Site 2 Dataset Fixed'\")\n",
    "print(\"View the Results below\")\n",
    "run_results.raw_response().json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Site 3 Data Harmonization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting to run harmonization on site 3 data\")\n",
    "output_dataset, \n",
    "run_results = site3_dataset.run_code(site_3_code, \n",
    "                                    output_data_schema_uid=dataschema.uid, \n",
    "                                    output_dataset_names_suffix=\" Fixed\")\n",
    "print(\"Finished running harmonization on site 3 data\")\n",
    "\n",
    "print(\"You can now see a new dataset in the GUI named 'Site 3 Dataset Fixed'\")\n",
    "print(\"View the Results below\")\n",
    "run_results.raw_response().json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Import updated datasets\n",
    "\n",
    "Now let's imagine you have some updated data (*_part_2.csv files). That you would like to harmonize in a similar fashion. Making simple modifications to the code above we can harmonize the new data with little effort.\n",
    "\n",
    "First let's import the updated data as new datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the paths here according to where you placed the files on you client\n",
    "dataset1_part2_path = \"/rhino_data/tutorial_2/datasets/site1_part2_dataset.csv\"\n",
    "dataset2_part2_path = \"/rhino_data/tutorial_2/datasets/site2_part2_dataset.csv\"\n",
    "dataset3_part2_path = \"/rhino_data/tutorial_2/datasets/site3_part2_dataset.csv\"\n",
    "\n",
    "# Alternatively, if you have access to the access to client-mounted storage, use something like the following:\n",
    "# dataset1_part2_path = \"/rhino_data/external/s3/tutorial_2/site1_part2_dataset.csv\"\n",
    "# dataset2_part2_path = \"/rhino_data/external/s3/tutorial_2/site2_part2_dataset.csv\"\n",
    "# dataset3_part2_path = \"/rhino_data/external/s3/tutorial_2/site3_part2_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_creation_params = DatasetCreateInput(\n",
    "    name=\"Site 1 Dataset - Part 2\",\n",
    "    description=\"Updated diabetes dataset for site 1 - part 2\",\n",
    "    project_uid=project_uid, \n",
    "    workgroup_uid=workgroup.uid,\n",
    "    data_schema_uid=dataschema.uid,\n",
    "    csv_filesystem_location=dataset1_part2_path,\n",
    "    is_data_deidentified=True,\n",
    "    method=\"filesystem\",\n",
    ")\n",
    "site1_part2_dataset = session.dataset.add_dataset(dataset_creation_params)\n",
    "print(f\"Created new dataset '{site1_part2_dataset.name}' with uid '{site1_part2_dataset.uid}'\")\n",
    "\n",
    "dataset_creation_params = DatasetCreateInput(\n",
    "    name=\"Site 2 Dataset - Part 2\",\n",
    "    description=\"Updated diabetes dataset for site 2 - part 2\",\n",
    "    project_uid=project_uid, \n",
    "    workgroup_uid=workgroup.uid,\n",
    "    data_schema_uid=dataschema.uid,\n",
    "    csv_filesystem_location=dataset2_part2_path,\n",
    "    is_data_deidentified=True,\n",
    "    method=\"filesystem\",\n",
    ")\n",
    "site2_part2_dataset = session.dataset.add_dataset(dataset_creation_params)\n",
    "print(f\"Created new dataset '{site2_part2_dataset.name}' with uid '{site2_part2_dataset.uid}'\")\n",
    "\n",
    "dataset_creation_params = DatasetCreateInput(\n",
    "    name=\"Site 3 Dataset - Part 2\",\n",
    "    description=\"Updated diabetes dataset for site 3 - part 2\",\n",
    "    project_uid=project_uid, \n",
    "    workgroup_uid=workgroup.uid,\n",
    "    data_schema_uid=dataschema.uid,\n",
    "    csv_filesystem_location=dataset3_part2_path,\n",
    "    is_data_deidentified=True,\n",
    "    method=\"filesystem\",\n",
    ")\n",
    "site3_part2_dataset = session.dataset.add_dataset(dataset_creation_params)\n",
    "print(f\"Created new dataset '{site3_part2_dataset.name}' with uid '{site3_part2_dataset.uid}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Harmonize data reusing the previous harmonization code\n",
    "The new Part 2 datasets suffer from the same inconsistencies as the Part 1 datasets.\n",
    "You can easily fix this by running the same preprocessing code you have defined eariler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Site 1\n",
    "print(\"Starting to run harmonization on site 1 - part 2 data\")\n",
    "output_dataset, run_results = site1_part2_dataset.run_code(site_1_code, output_data_schema_uid=dataschema.uid, output_dataset_names_suffix=\" Fixed\")\n",
    "print(\"Finished running harmonization on site 1 - part 2 data\")\n",
    "print(\"You can now see a new dataset in the GUI named 'Site 1 Dataset - Part 2 Fixed'\")\n",
    "\n",
    "# Site 2\n",
    "print(\"Starting to run harmonization on site 2 - part 2 data\")\n",
    "output_dataset, run_results = site2_part2_dataset.run_code(site_1_code, output_data_schema_uid=dataschema.uid, output_dataset_names_suffix=\" Fixed\")\n",
    "print(\"Finished running harmonization on site 2 - part 2 data\")\n",
    "print(\"You can now see a new dataset in the GUI named 'Site 2 Dataset - Part 2 Fixed'\")\n",
    "\n",
    "# Site 3\n",
    "print(\"Starting to run harmonization on site 3 - part 2 data\")\n",
    "output_dataset, run_results = site3_part2_dataset.run_code(site_1_code, output_data_schema_uid=dataschema.uid, output_dataset_names_suffix=\" Fixed\")\n",
    "print(\"Finished running harmonization on site 3 - part 2 data\")\n",
    "print(\"You can now see a new dataset in the GUI named 'Site 3 Dataset - Part 2 Fixed'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your datasets are now harmonized! Use the filters on the Dataset Analytics tab in the GUI to visualize the results.\n",
    "# End of tutorial 2! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
